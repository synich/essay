Python进阶学习点滴
====
迭代与惰性
--
iterator概念体现在很多地方，甚至str都可以迭代，list('abc')会返回['a','b','c']。具备迭代的函数又分eager和lazy两种，list是eager行为，enumerate/map则是lazy行为，返回一个可迭代对象，对这个对象用for循环或tuple/list进行求值。

lazy对象一旦被求值，这个对象就成了空壳，因为lazy对象从语义上就不把值放在内存，可以理解为外部源的一个门户或代理，当真正的外部源被求值完毕，则lazy代理自然没有了内容来源。

内建3大基础类型tuple/list/dict都具备对lazy迭代对象求值的能力，dict因为语义原因，每次迭代必须有两个值。

求值是严格模式，要想实现惰性，由于缺少宏和编译期展开能力，能想到的办法只有foo(lambda: x)，然后在函数体内展开。

多行lambda
--
语法上要求返回一个expression，不能出现冒号和赋值（因为赋值是statement，可以用3.8后的:=assignment expression）。利用tuple和切片索引来打包多个独立行为，利用if的一行式来做简单的条件

```
def main(n):
    return lambda x: (
    print(x),
    x+1 if x > 0 else x-1,
    x + n)[1:]
```

多线程
--
拜臭名昭著的GIL所赐，多线程只在IO密集场景下有一战之力。即便只能用到一个核，锁还是必须的，但这个锁和OS的锁不同，是语言级别的锁，不会触发futex调研。有人解释说这种锁的获取和释放，会引起GIL的调度，暂时不能确定。另外py3新增了asyncio后，多线程的使用场景似乎更少了。

多进程
--
多进程库有两种构造进程的方式，Process（构造一个）和Pool（构造多个功能相同的进程）。从实际效果来看，每生成1个进程，实际会生成2个线程。以生产消费模型，结合队列来举例子。

先说队列Queue，生产者用put方法，消费者用get方法，但是这里有个隐秘且反直觉的地方，调用put会将队列的计数加1，但get并不会减1，需要在get之后再调用task_done才行，背后的原因是get允许异步获取，所以必须消费者确认得到消息后，才能将队列次数减1。队列的次数可以通过empty方法得到。真实代码中，生产者会用队列的join方法，join会阻塞直到队列为空才执行下去。

就产生了这样一种方式，消费者用with Pool结构，在这个结构内，用Process来创建生产者，生产者全部start()后，会挨个join()，直到每个生产者执行中，队列的join通过后，才会结束。*注意，这里有两个join，分别作用在队列和进程上，而进程的join又被队列的join所阻塞，最终等待消费者消费完所有消息，这就构成了完整的闭环*。当生成者结束后，with语句块的生命周期结束，调用Pool的`__exit__`方法，它又触发了Pool的terminate()，将所有消费进程强行停止，于是所有进程就都正常回收了。

一开始我看这段还很疑惑，为什么while Tue循环里只有队列的get，看不到判断和退出，其它是用了with块的方式强行中止了进程，自然就不用判断队列。

JoinableQueue objects should only be shared between processes through inheritance

Pool创建的进程，和Process没有继承关系。跟踪系统调用发现，都是用clone函数，无非用的标志位不同

* CLONE_VM: VM shared between processes，内存共享，大约等于线程
* CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID:  Store child thread ID in child memory.Erase child thread ID in child memory space when child exits.
* CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID: 

进程池
--
使用进程池Pool启动多进程建议用`apply_async`，这个方法默认不会阻塞，想要等待必须连用Pool的close和join方法，网上文章几乎不提为什么。看了源码才知道，Pool有4种状态，INIT，RUN，CLOSE，TERMINATE。构造进程池对象时，内部会经由INIT状态切到RUN状态。CLOSE状态是为了配合join使用，如果不切换到CLOSE状态，join动作会报错。join内部调用到的方法有wait，只是觉得都用join还是有些混淆。

多进程的队列
--
底层使用操作系统的pipe作为传输，但为了实现任意py对象的传输，在数据写队列前，会先用pickle序列化，读出的一方会先确认pipe内的消息长度，读出后再反序列化。复杂队列的实现，发送者每次发一条消息，会创建一个线程，由这个新的线程向pipe写数据。

defaultdict
--
出人意料的是这个容器是builtin的，实现在`_collection`包中，不是一个独立的磁盘文件，而是和C语言实现打包在一起，可能对字典的操作需要极高的性能，因此无法用py实现吧。

namedtuple
--
是一个函数返回一个用type方法动态构建的类

pickle序列化
--
首字节固定0x80，然后跟1字节的版本号，截止3.8共有1-5的版本。

每遇到新的复杂结构（tuple/list/dict），都会写入一个新的标记符，`EMPTY_XX`，然后跟着具体的值。

结构内的字符串，以类型+长度+值的方式保存（典型的TLV格式）。

字典内容都结束后，以一个's'（SETITEM动作）把kv的pair对加入字典。

最后以'.'结尾这个pickle。

当然过程中会用MEMOIZE技术复用已保存的字符串，达到节约空间的效果。整个pickle不仅仅记录了值，更记录了从一片空白到完成所有对象的整个操作步骤，在构建过程中逐步还原出对象。

魔术方法
--
`__getitem__`作用于方括号下标，而`__getattr__`作用于对象的点式取值。还有要注意的是，这两个方法虽然是class上定义，但却只对实例后的对象生效。

类型标注
--
初看`Union[int, str]`语法会觉得很困惑，因为下标引用只能是1个值，但是换成Union(int, str)又会提示不是callable，说明只能是`__getitem__`方法，再自己实现后才明白原来[int, str]会被转换成[(int, str)]形式。

Optional基于Union扩展，但做的时候偷了个懒只能传递单参数，因此实际用的时候往往会写成`Optional[Union[]]`形式。

源码初读
--
几个关键目录的目标

* Object和Python： 定义对象的内存布局，核心的so要实现的编译及导入功能
* Lib： py实现的标准库
* Modules： py库会引入c实现的so(lib-dynload目录)，都在这里实现
Parser和Grammar： 词法语法解析