# SQL的JOIN种类与选择

JOIN分单机和分布式，但是单机是基础，共有3种

1. Nest Loop Join: 最简单但性能也最低，拿左表的每一行，从右表循环匹配，复杂度O(MxN)。过程中可以利用右表的索引来加速。
2. Sort Merge Join: 将两张表分别进行排序，然后再扫描的时候，因为顺序已经固定，所以就不需要做全表扫描，因此连接的复杂度是O(M+N)。不过考虑到对两张表排序的成本, 不能过分乐观。
3. Hash Join: 将小表的joinkey和关联内容提取出来，对joinkey列做hash，得到中间表保在在内存，对大表做scan并按同样的hash去内存中找到匹配记录

对于常见的等值连接来说，如果小表的内容足够小，都会采用Hash的方式。要注意的是，这个足够小，并不是仅指joinkey，而是要把关联的内容一起算上看总大小。

Nest Loop尽管复杂度高，但在不等值连接的时候一般都用这种方式，因为Sort Merge要求表必须做排序，而排序的成本不低，所以权横后还是会选择用的Nest Loop。

分布式场景怎么又增加了shuffle和broadcast这两种策略，和单机版组合理论上一共有6种策略。但是spark放弃了broadcost和sort merge组合，比hash性能不足，能力上又不如NestLoop，因此最终就只有5种策略。

semi和anti
--
这两种都是从子查询优化中演化出来的，也间接说明原生几种join的表达力不足。

left semi join表示半的语义，具体有这几条

1. 只能select左表数据，这也是semi最核心的含义
2. 结果不会受右表关联重复数据的影响，从第一点可以看出，右表只是用于关联，不参与结果构建，也就不会导致重复
3. 必须搭配left/right其中一种，不能单独semi，否则无法确定取哪一半

anti表示的反，等效与先left再取右边为null，但写起来方便。可以left anti join，也可以直接t1 anti join t2取t1有而t2没有的数据。

这两种更像子查询优化而不是独立语义，所以没在标准中找到，但部分实现会支持。
