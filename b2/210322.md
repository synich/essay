对公有云上数仓的调研
==
Snowflake的数仓产品在架构上分为三级，从下到上的功能分别是（以Amazon为例，这块有论文相对详细，MG两家没什么资料）

1. DataStorage：基于Amazon S3，存储数仓数据。选型时在S3和自建HDFS间有过权衡，最终还是选择了S3，从经济上更合算，且关注点聚焦在应用层。
2. VirtualWarehouse：每个VW由数量不等的Amazon EC2弹性计算实例构成，在向用户销售时，使用S->M->L这种服务尺寸，用户看不到EC2的数量。由于计算规格的单价已经分档，后续的付费就是基于时间来计费，Snowflake还贴心地给用户提供了超过多少时间停用的选项，有点类似运营商流量套餐超限保护，避免按调用次数付费场景下，写出了烂SQL，结果账单爆表的问题。
3. CloudServices：这块是Snowflake的核心自研产物，包括SQL执行引擎（三大特性：列存、向量化、push方式，上游主动给下游推数据，据说能提高缓存效率，之前很多引擎，都是基于Volcano模型的pull方式）、表的元数据管理（KV形式存储）、并发控制和事务管理。

计算存储分离

业界有一种主流的架构称为Shared-Nothing，指对一个很大的表数据，系统把它按照某种规则拆分成N份，拆分之后由N个worker来分别处理其中的一个分区。这样的好处是架构比较简单，所有worker上的处理逻辑都一样，worker节点之间不共享任何数据，查询执行的过程中没有资源的争抢，效率很高，而且拆分之后普通的机器就可以计算很大的查询，不再需要什么特殊的高配机器。它最大的缺点是，把计算资源和存储资源捆绑在一起，引起以下问题：

1.  当集群的节点数发生变化(升级，扩缩容等等)的时候，Shared-Nothing 需要对数据重新进行分布，而这个是需要消耗大量的计算资源的，在这期间用户在线查询的性能会受到影响。
2.  不同场景对于机器配置的要求不一样，一个对于数据导入很好的配置(IO intensive)对于复杂的在线查询(CPU-intensive)就不一定适合，而为了支持所有的场景，最后机器的配置要取个折中，从而无法达到最好的性价比。
3.  集群的软件版本有升级的需要。虽然理论上可以一个接着一个地升级，但是工程实现会很复杂。

由于Snowflake把存储和计算分别部署在S3和EC2上，实现了分离。对前面提到的Shared-Nothing的几个问题，对于异构工作负载的问题，用户可以为不同的场景分配不同的计算层机器，用完了之后可以释放掉（这点和Snowflake的计费模式也有关）。又因为EC2和S3没有任何关系，在计算节点扩缩容时，当然不需要对数据进行重分布操作。
 
技术特性问答

* 如何解决存算分离带来的性能问题？

每台Worker节点都配备了SSD，这个SSD并不保存原始数据，而是保存被之前查询请求过的热数据，做到在性能和成本间的平衡。为了提高缓存文件的磁盘命中率，Snowflake的查询优化器在调度TableScan的时候会根据表对应的底层文件名，以一致性hash的算法把数据加载的请求分到这些worker节点上，保证对同一个文件的请求可以尽量落到同一个worker节点上去，提高命中率。
因此从大的架构来看Snowflake做了计算和存储的分离，但是如果看缓存的设计，会发现计算和存储又绑定到一起了。只不过这个绑定不明显，而且只存储被查询的数据，不是全量数据。

* 如何实现更新？

Snowflake系统里面的数据文件都是只读的，当用户对数据进行更新的时候，系统会产生新的文件，把老的文件替换掉，但是每个文件本身是只读的，这样的模式特别适合S3的存储特性（只能覆盖写，不能追加写），同时也方便实现MVCC -- 只要让每个查询始终读查询开始时的对应的版本的文件就好了。

* 如何实现事务？

事务是通过 Snapshot Isolation的方式来实现的，所谓的Snapshot Isolation, 指的是一个查询能看的数据是这个查询开始时整个系统的一个快照，跟类似系统一样，Snowflake也是通过MVCC来实现Snapshot Isolation的。

* 为什么不用索引？

1. 索引依赖对文件随机读，而S3系统并不适合随机读取。
2. 索引会降低查询、加载的效率，数仓数据量都特别的大，降低了加载的效率在需要做数据恢复的时候是很大的问题。
3. 索引需要用户手动创建，会加重用户使用成本。

* 索引的替换方案是什么？

在每个数据文件上保存数据的min/max类统计数据，通过对这些元数据进行扫描可以判断是否要扫整个文件，避免扫描所有文件。这种方案在顺序大块数据时效果很好，对数据载入、查询优化、查询执行的影响也非常小。
Snowflake对半结构化的列也会生成min/max。除了静态剪枝，Snowflake还会运行期动态剪枝。例如在hash join时，Snowflake会在构建端统计join key的分布，再传到探测端用来过滤数据，甚至有机会跳过整个文件。

* 如何做到数据加密？

数据会在两个地方加密，一个是网络传输时，一个是磁盘写入时（如Amazon S3）。
存储数据的加密滚动策略：磁盘上保存数据用的加密key是一直在变化的，具体策略是定期创建新的key，之后旧的key只用来解密，不能再加密了。当确定一个key要被弃用后，用这个key加密的文件会被用新的key重新加密。