# 写文件的一些特性

先创建一个分区，方式如下

* `dd if=/dev/zero of=./dummy count=204800` 创建一个普通文件，用file看类型是data
* `mkfs.ext4 ./dummy` 会提示不是个block special device，是否要继续。选Y继续。将普通文件用ext4的方式格式化，进而可以挂载。block大小1K，每个inode管理约4个block。预留5%的block给root用户，journal占4096block。文件变成了filesystem data类型
* `mount ./dummy /tmp/` 将block文件挂到指定目录

磁盘满有空间满和inode用完两种情况。inode用完主要是小文件过多导致，此时空间是还有剩余的。一般跑服务器程序不会有这么多小文件，重点关注磁盘剩余空间。

分别用fwrite和write测试连续256次写入一些数据。

* 4K粒度，每次用3到9us，隔20次左右会突然有次达到30us，最大44us。
* 8K粒度，每次用5到9us，但隔10次左右就会耗时增加，大约20略大us，最大78us。
* 16K粒度，开始5us，到最后几次达到20us，突变时约30us，但有一次特别大，达到25ms。
* 32K，每次最少20us，后来到达150us。突变峰值32ms。

当空间快占满时，写4K的速度几乎没有变化，10us左右，波动仍是30us。当写完后，每次写的时间仍然差不多，但100多次才出现2、3倍的小波动。

用df看磁盘空间，当avail显示是0时，root仍然能继续写入一定量的数据，普通用户如果是0那就真不能写了。写空间从有到没有的一瞬间，会出现写入耗时的峰值，约是10us到10ms放大1000倍，在那之后写入速度基本就是个2到3us的恒定值。

df和du查看磁盘区别
--
这两个命令都能统计分区大小，原理不一样。df读磁盘的superblock分析空间和文件系统属性，而du是用stat系统调用遍历每个文件或目录，最后得到总和。因此速度要慢很多。