# 系统性能分析的理解

曾经以为性能分析一定要用看起来很高深的工具，实际上重点还是在于对系统各个方面的理解。对《性能之巅》观测指标做个分类，分为软件和硬件，软件类包含操作系统、文件系统和进程，而硬件包含CPU、内存、磁盘和网络。

## 进程状态

ps会显示多种状态

* S 可中断睡眠，可以被外部信号或内核唤醒，比如网络等待
* D 不可中断睡眠，只能被内核唤醒，比如读写磁盘，虽然不占CPU但占着其它硬件，且必须一直拿着这个硬件，否则会导致硬件损坏
* T或Z 停止或僵尸

另有几种文档说BSD状态，但好像也会显示

* <和N 高低优先级
* s session leader
* l 多线程
* \+ 前台进程组，不理解，似乎不重要

## CPU

最粗略的观察通过uptime和top，看变化趋势和整体分布，要注意的是load和usage是不是维度的度量，两者甚至可能出现很大的偏差。因为load统计可以大体等同于R和D状态的进程总数，表示运行中的进程数，但是D状态不会占用usage，所以如果出现有大量读磁盘的进程时，load会明显高于usage；理论上猜测（没有遇到过），当进程数较少，但某些进程使用多核计算，会出现usage高于load的情况。

CPU的计时分了很多状态:  usr, sys, nic,  idle,  io(wa),   irq(hi),   sirq(si)

usr、sys和nic是某个进程的耗时，nic是低优先级(1~19)进程的用户态耗时，而io、irq计算整个系统的耗时，类似于公摊，不计入进程耗时。进程还要观察上下文切换，也会导致CPU过高。

## 内存

内存首先分为物理内存和虚拟内存（swap分区）。

内存有cache和buffer。buffer对应block device，比如文件系统的MetaData，量并不大，知道就好不用太关注。

cache比较重要，它表示程序曾经往Disk写入的数据，除非系统判断内存不足，不会去清理cache，所以经常看起来很大，但不必担心。

ps有个-o选项，可以输出非常多的信息，说说内存。

* rss，resident set size，表示常驻物理内存的大小。这里有个要注意的，在计算so共享库的时候，会全部计算进去，实际上so的多存往往是多个进程共用，对系统的占用并没有表面上来得严重。累计了CODE段和DATA段的总大小。用pss做总和才是正确的值，p表示比例，共享的内存按比例均分。
* sz，比rss大
* vsz，虚拟内存，最大。等于swap和rss总和。

另有pss(proportional set size)是将so内存按比例统计，对每个进程来说更准确。uss则完全不计入so内存。

pmap可以给出更细的检测报告，每个so库的每种段，堆和栈占用多少内存全部统计分明。

内存在系统中有4种状态

1. 未载入(不用关心)
2. 已载入，但未映射
3. 已载入，且已映射
4. 已载入，但被换到虚拟内存

通过工具看到最多的，3代表常驻内存RSS，2,3,4合起来又名VSS

监测可以针对系统级进程。监测的原理分为计数器和跟踪，另外profile也有，但使用面会窄些。

* 计数器方式：由于内核本就维护各种统计数据，因此计数方式的采集可以认为是零开销。基于计数器方式有sysstat工具包，涵盖了一系列专项的工具，如pidstat/mpstat/iostat等。另外sar是system active report的简写，虽然没有stat但也是sysstat的一员。其它各自针对不同资源进行监测。还有一个procps-ng包，包括了vmstat/free/ps/top等经常会用到的工具，形成两大派别。netstat是早已有之，不在这两个派别内。
* 跟踪方式：又叫事件，系统级典型如perf/systemtap，进程级有strace/gdb，基于系统事件方式的采样。找到哪个环节出问题，针对性的采集数据。Perf是Linux内核自带的性能监测工具，自2.6.31版开始引入所以发行版都会带这个功能。它配合内核的`perf_events_open`接口(也是perf惟一的接口)使用。而systemtap更像是CentOS专门的工具，默认不带要另外安装。

## 计数器方式

计数器方式可以很快地看出系统的负载，最复杂的命令是sar，用sar -A可以看到所有数据，底层有sadc(采集数据)和sadf(输出格式化数据)支持。再说几个工具的特性。

iostat可以监视IO(-d)和CPU(-c)，类似的top命令观测CPU时也有iowait指标，也体现了IO的度量，IO不仅受磁盘影响，也会影响CPU的使用率。

pidstat从名字可以看出，用于找出问题出在哪个进程，指标包括IO，内存缺页，栈的使用大小。

## 跟踪方式

2.5版本内核支持了ftrace特性，并以tracefs文件系统方式展现给用户。如果打开了该特性，可以在/proc/mounts查找tracefs的挂载点，并切换到root（sudo不行！）进入该目录（一般是/sys/kernel/debug/tracing/）。既然是类文件系统，通过修改文件来打开跟踪和观察。这种方式操作不友好，trace-cmd包可以简化一些。ftrace的实现依赖于内核在gcc编译阶段留的桩，编译内核的参数缺省会用"-pg -mfentry -mrecord-mcount"，前两个参数给每个函数开头插入5个字节的callq指令，而最后一个参数则在vmlinuz的`mcount_loc`段记录了所有内核函数的地址。但是所有函数都留桩显然开销太大（下降13%），所以ftrace在内核启动时会callq指令替换成nop指令。当用户对特定函数开启了追踪，用callq替换nop，将追踪信息写入ring buffer输出给用户。

2.6版本出现了perf，因为ftrace只管抓trace数据并没有分析，perf在trace数据分析方面做出了很多成果。在trace数据采集方面，perf复用了ftrace的所有插桩点，并且加入了采样法(硬件PMU)。PMU是一种非常重要的数据采集方法，因为它大部分是硬件的，所以可以做到一些软件做不到的事情，获取到一些底层硬件的信息。

> PMU是什么：像L1 cache失效、分支预测失败等几种处理器特性对软件的性能有很大的影响，然而依赖时钟进行定期采样的 profiler 模式无法揭示程序对这些处理器硬件特性的使用情况。处理器厂商针对这种情况，在硬件中加入了 PMU 单元，即 performance monitor unit。PMU 允许软件针对某种硬件事件设置 counter，此后处理器便开始统计该事件的发生次数，当发生的次数超过 counter 内设置的值后，便产生中断。比如 cache miss 达到某个值后，PMU 便能产生相应的中断。捕获这些中断，便可以考察程序对这些硬件特性的利用效率了。

BPF源于1992年的Berkeley Packet Filter论文，触发Linux社区在97年也跟进并实现了Linux Socket Filter机制，但长久以来只有tcpdump这个应用。BPF原理如下图。经网卡驱动层的报文在上报给协议栈的同时会多出一路来传送给BPF，再经后者过滤后最终拷贝给用户态的应用。除开tcpdump，当时的 RARP 协议也可以利用 BPF 工作(Linux 2.2  起，内核开始提供 rarp 功能，因此如今的 RARP 已经不再需要 BPF 了)

![bpf-germ](/img/bpf-germ.jpg)

其中的filter是类似汇编码的指令，为了防止注入，对BPF的指令做了很多数量和长度的限制。由于内核态开销大，3.x时代出现了JIT for BPF，2013年对BPF做了彻底重写，命名为eBPF，最终在3.17时代进化出全新的eBPF，并持续发展了seccomp、XDP、traffic control等机制。