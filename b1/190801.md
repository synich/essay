数据库和数仓的历史
====
数据库是计算机最早的应用系统，阿波罗计划时就有了数据库原型，这便是1968年的IBM ICS系统，69年改名为IMS/360（层次型数据库）。70年，IBM的研究员Codd提出了关系型模型，虽然关系型理论是IBM提出的，但出于产品惯性IBM没有及时跟进，反而是1983年Oracle率先向市场推广，虽然同年稍晚IBM也发布了DB2产品，但在市场上显然是Oracle胜了。

和数据库相关但又有区别的数据仓库（Data Warehouse），概念早在1970年代就有探讨，Inmon在Kimball分别在1992和1996年出版关于数仓的专著，可以认为数仓正式成型。Inmon定义数仓是一个面向主题的（Subject Oriented）、集成的（Integrate）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。或者说就是建立围绕主题，并最终要挖掘出主题间关系的库。落地到具体行业，一定要对行业关心的主题建立好模型。支持构建完整数仓的技术有：清洗、集成、OLAP。

* OLTP: 联机事务处理， 关系型数据库(Oracle、MySQL)多属于此类，擅长记录发生的业务内容，多小批量写入，要保证事务性。设计时强调三范式，表结构紧凑，避免冗余
* OLAP: 联机分析处理，随着OLTP的数据越来越多，如何快速地分析这些数据就变得重要起来，这个概念是Codd在1993年提出的，在设计上和OLTP不同，往往把多张表JOIN成宽表，保留一定的冗余，来提升分析和处理速度，并不在意事务能力。分析使用的技术，多为统计学或机器学习方法。

数据仓库的来源分为非结构化和结构化数据。非结构化数据要先经NLP提取变为结构化，结构化数据可以用机器学习的方式做分类、聚类，又或者按统计学的方式进行提取。

数仓的建模方式有多种，国内主流的是阿里推崇的维度建模(kimball)，有星形模型(一个事实表和多个维表，没有二级维表)和雪花模型(在星形基础上允许二级甚至更多级维表)。

MPP与SQL on Hadoop
--
支撑数仓的软件有很多，其中一个大类统称MPP，比较商业的产品是金融领域的TeraData，但价格太贵，多见的是GreenPlum，是基于Postgre开发的主从式分布数据库，master负责调度segment负责执行。引申一句GP最初是EMC开发的，买存储送GP，配合EMC的存储和售后，在银行领域很有竞争力。

MPP的代表产品有：Vertica/Redshift(Paracel，被Amazon买下了源码的license后变成Redshift)/Greenplum。仔细观察不难发现，这三者其实有非常很多相同点：

1. 全部基于PostgreSQL
2. 都是基于列的存储(Columnar Storage)
3. 操作都是以Scan为基础，依赖Compression来提供性能的优化

MPP为了速度，需要将数据导入做一定处理，整理成优化的格式以便加速。这样做的后果就是，它们的存储类似一个黑盒，数据进去之后很难被别的系统直接读取。

还有另一类统称SQL on Hadoop，实现有Impala，Hive，SparkSQL，Presto等。这类方案不负责存储，或者说是存算分离，计算基于MapReduce/RDD机制，水平扩展性很强。但是这种方案是多种系统共用一个HDFS存储空间，不可能做非常彻底的优化时优化，典型的就是CBO优化程度会弱一些。

SQL-on-Hadoop架构可以分为两类：

1. SQL over Processing Framework：例如SparkSQL，Drill/Datameer，Presto，Impala
2. OLAP over Hadoop：例如Kylin，Druid，AtScale，Kyvos

SQL over Processing Framework系统的共同特点是“Hadoop通用计算框架+SQL解析引擎”，存储层、执行引擎层、SQL解析层三者分离，可以方便替换执行引擎，对使用者而言，同一份数据可以采用不同并行执行引擎来分析。优点是灵活性高，支持细粒度容错，集群扩展性好，缺点是效率无法保证。

OLAP over Hadoop系统的共同特点是预计算，即数据都以时间序列的方式进入系统并经过数据预聚合和建立索引，因为是预计算，所以应对多维查询时速度非常快（计算时间复杂度O(1)）且稳定，支持高并发，支持集群扩展。缺点是灵活性较差。

MPP原理朴素上说就是分治思想，均分task。
然后每个worker/segment上做的都是同样的sub-task，pipeline方式执行，理想情况下性能是非常优异的。
但是很容易受到慢worker（它是最长路径）和interconnect的影响，所以scalability不佳，集群规模在十几个节点后就没有性能提升了（甚至还可能下降）。

HADOOP原理更类似batch processing，更细粒度切分task，worker能者多劳（每个worker上执行的任务可以是不平均，不一致的）。
单独worker看，性能不及MPP，但是胜在scalability优异，几百个节点是没问题的，在集群性上远胜MPP。

MPP和SQL on Hadoop的最大区别在于，MPP架构是Full-SQL compatiable的，实现不局限于将Query分解为一连串的job去执行。并且由于每一列的数据类型进行了特定的压缩和编码(比如run-length/delta/bytecoding)，能做的优化要比单纯的MapReduce多很多，效率自然也要高不少。相较于SQL on Hadoop，MPP更适合做interactive ad-hoc analysis，前者则更适用于对于海量数据做批处理或者需要使用UDF(自定义函数)的场景。