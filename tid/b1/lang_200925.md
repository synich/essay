# Python进阶学习点滴

## 函数式构件

### 装饰器

装饰器是一个至少要接受1个参数的函数，但如果想再多接受参数，反而不容易，必须要用partial方式封装，看示例

```
def before(f=None, arg=None):
    import functools
    print("before", f, arg)
    return functools.partial(before, arg=arg)  # 不能写成 return before

@before(arg=3)
def foo(i):
    print("foo", i)
    return i+i
```

装饰器会影响函数定义，使 *定义* 行为变成了 *执行* 行为，或者说在 *编译* 阶段发生了 *运行时* 行为。以上面代码为例：哪怕不调用foo函数，before函数也会执行。所以装饰函数的行为一定要慎重，一不小心就会产生副作用。

@方式在函数外部引入的装饰器，会导致实体函数的元属性被装饰器拦截，如果想保留实体函数的元属性，看示例

```
from functools import wraps # 引入functools模块的wrap装饰器方法

def repeat_twice(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        func(*args, **kwargs)
        func(*args, **kwargs)
    return wrapper

@repeat_twice
def foo():
    print 'hello world'

print foo.__name__      # Out: foo
```

### 多行lambda

语法上要求返回一个expression，不能出现冒号和赋值（因为赋值是statement，可以用3.8后的:=assignment expression）。利用tuple和切片索引来打包多个独立行为，利用if的一行式来做简单的条件

```
def main(n):
    return lambda x: (
    print(x),
    x+1 if x > 0 else x-1,
    x + n)[1:]
```

## 并发

### 多线程

拜臭名昭著的GIL所赐，多线程只在IO密集场景下有一战之力。即便只能用到一个核，锁还是必须的，但这个锁和OS的锁不同，是语言级别的锁，不会触发futex调研。有人解释说这种锁的获取和释放，会引起GIL的调度，暂时不能确定。另外py3新增了asyncio后，多线程的使用场景似乎更少了。

### 多进程

多进程库有两种构造进程的方式，Process（构造一个）和Pool（构造多个功能相同的进程）。从实际效果来看，每生成1个进程，实际会生成2个线程。以生产消费模型，结合队列来举例子。

先说队列Queue，生产者用put方法，消费者用get方法，但是这里有个隐秘且反直觉的地方，调用put会将队列的计数加1，但get并不会减1，需要在get之后再调用task_done才行，背后的原因是get允许异步获取，所以必须消费者确认得到消息后，才能将队列次数减1。队列的次数可以通过empty方法得到。真实代码中，生产者会用队列的join方法，join会阻塞直到队列为空才执行下去。

就产生了这样一种方式，消费者用with Pool结构，在这个结构内，用Process来创建生产者，生产者全部start()后，会挨个join()，直到每个生产者执行中，队列的join通过后，才会结束。*注意，这里有两个join，分别作用在队列和进程上，而进程的join又被队列的join所阻塞，最终等待消费者消费完所有消息，这就构成了完整的闭环*。当生成者结束后，with语句块的生命周期结束，调用Pool的`__exit__`方法，它又触发了Pool的terminate()，将所有消费进程强行停止，于是所有进程就都正常回收了。

一开始我看这段还很疑惑，为什么while Tue循环里只有队列的get，看不到判断和退出，其它是用了with块的方式强行中止了进程，自然就不用判断队列。

JoinableQueue objects should only be shared between processes through inheritance

Pool创建的进程，和Process没有继承关系。跟踪系统调用发现，都是用clone函数，无非用的标志位不同

* CLONE_VM: VM shared between processes，内存共享，大约等于线程
* CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID:  Store child thread ID in child memory.Erase child thread ID in child memory space when child exits.
* CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID:

### 进程池

使用进程池Pool启动多进程建议用`apply_async`，这个方法默认不会阻塞，想要等待必须连用Pool的close和join方法，网上文章几乎不提为什么。看了源码才知道，Pool有4种状态，INIT，RUN，CLOSE，TERMINATE。构造进程池对象时，内部会经由INIT状态切到RUN状态。CLOSE状态是为了配合join使用，如果不切换到CLOSE状态，join动作会报错。join内部调用到的方法有wait，只是觉得都用join还是有些混淆。

### 多进程的队列

底层使用操作系统的pipe作为传输，但为了实现任意py对象的传输，在数据写队列前，会先用pickle序列化，读出的一方会先确认pipe内的消息长度，读出后再反序列化。复杂队列的实现，发送者每次发一条消息，会创建一个线程，由这个新的线程向pipe写数据。

## pickle序列化

首字节固定0x80，然后跟1字节的版本号，截止3.8共有1-5的版本。

每遇到新的复杂结构（tuple/list/dict），都会写入一个新的标记符，`EMPTY_XX`，然后跟着具体的值。

结构内的字符串，以类型+长度+值的方式保存（典型的TLV格式）。

字典内容都结束后，以一个's'（SETITEM动作）把kv的pair对加入字典。

最后以'.'结尾这个pickle。

当然过程中会用MEMOIZE技术复用已保存的字符串，达到节约空间的效果。整个pickle不仅仅记录了值，更记录了从一片空白到完成所有对象的整个操作步骤，在构建过程中逐步还原出对象。

## 类型和类

从大的分类来说，有两种分类，类型（Type）和实例（Non-Type）。类型中有两个特殊的存在，type和object。所有的内置类型如tuple、list都继承自object（即`list.__bases__`是(object,)），同时它们的type就是type（即`list.__class__`是type）。

所有的值，不管是简单的数字、字符串、None或复杂的容器类型，都有所属的class。不同的class具备的特性不同，比如sequence属性就是tuple/list/str还有range类型特有的(range不仅是一个函数，其生成对象的类型就是range，可以迭代)。

### 继承体系

从py3开始，声明一个新的class默认继承自object，前面提过除了object外，还有个特殊的type，因为class关键字其实是对type的封装，class A:声明形式等价于A=type("A", (object,), dict=())，所有的类对象，都是type的派生（严格的说是type产生了metaclass，而由此再产生普通类）。

py支持多继承，使用MRO解析方法调用顺序，这就对继承有了约束。比如B(A)，那么只能C(B, A)，不可以C(A, B)，因为后者无法满足MRO的要求。当super作用在多继承的子类时，也只会解析出最优先的惟一类，不会把所有父类都调用一遍。

### 魔术方法

`__getitem__`作用于方括号下标，而`__getattr__`作用于对象的点式取值。还有要注意的是，这两个方法虽然是class上定义，但却只对实例后的对象生效。

### 类型标注

初看`Union[int, str]`语法会觉得很困惑，因为下标引用只能是1个值，但是换成Union(int, str)又会提示不是callable，说明只能是`__getitem__`方法，再自己实现后才明白原来[int, str]会被转换成[(int, str)]形式。

Optional基于Union扩展，但做的时候偷了个懒只能传递单参数，因此实际用的时候往往会写成`Optional[Union[]]`形式。

## 源码初读

几个关键目录的目标

* Object和Python: 定义对象的内存布局，核心的so要实现的编译及导入功能
* Lib: py实现的标准库
* Modules: py库会引入c实现的so(lib-dynload目录)，都在这里实现
* Parser和Grammar: 词法语法解析