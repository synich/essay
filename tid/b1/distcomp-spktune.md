# 12 spark性能调优记录

## 资源配置

和运行速度相关度最大的是instance数量，我做的业务因为数据量在千万以内，内存只有6G，实例数只会分配个位数。实测发现2个比1个提升明显（至少50%以上），3个比2个有提升但幅度开始减少（30%左右），再往上提升就更少了。而内存在保证不OOM的情况下，多给也只会减少JVM的GC时间，对性能没什么提升。

## udf和udtf

同行逻辑最初的版本是用udf做，尽管经过数次优化，但始终有内存占用过大问题，计算过程是先对点位分组，然后把每组的数据`collect_list`后交给udf来计算，pyspark的udf每次传递100条数据，到了这个逻辑传递的其实是100个分组，内存肯定很高。但细想会发现这其实这是个标准的udtf过程，于是想到换用udtf每次传递1个分组，内存肯定可以降下来。开始还担心由于传递次数变多，而且udtf得到的是pandas dataframe，需要转换成原生的list，会有性能下降，实测不仅内存确实减少，而且性能提升2倍左右。

这就涉及一个apache的跨项目的arrow库，所传随着大数据组件越来越多，组件间的数据传递成为一个大的开销，社区当然有人意识到这个问题，于是组织起来开发了arrow这个高效的序列化库，经过arrow序列化后的库，不需要反序列化，收到后放到内存就能直接用，udtf利用了arrow库，而udf并没有，说真的arrow对性能有这么大的提升，真的是没有想到。

换成udtf后在k8s会遇到程序终止问题，查看了instance内存，虚拟内存竟然用了9G。经人指点发现是numpy的内存占用受`OMP_NUM_THREADS`影响，默认和CPU核数一样，服务器40核所以内存占用极大。但是我开始验的时候，导入numpy只会多出200M左右的虚拟内存，过了一天意识到验证用的是anaconda，而pyspark是开源的python，开源版numpy依赖的openblas会依赖OpenMP，从环境变量名也可以看出就是OpenMP的行为，而anaconda的并行库是intel的MKL，不会根据CPU核创建这么多线程。

PySpark内存的使用分3部分

* jvm: 主要计算在这里完成
* overhead: 发生shuffle时，netty要用这块内存缓存网络数据
* python: 使用udf或rdd会占用

## 查看UI

正在运行中的代码，第一个job页会显示active job，下面还会有很多complete job。每个job会被分拆成一到多个task，task又会分到不同的instance执行，所以job执行完就表示代码中的一段逻辑完全运行完成，不用担心是否只是部分instance运行完。看tasks往往会看到很多标记了skipped，这里有很多原因：一方面可能是数据被缓存，所以跳过，另一方面也可能是数据倾斜，让引擎以为需要这么多task，但实际执行后发现没有数据，于是就跳过了。job和代码的映射关系还不清楚，但只要代码不改，job的数量就不会变化。