# Preempt机制

Preempt是一个32位的整数，每一个CPU有一个。虽然是一个简单的整数，但是作用非常大。一个当前运行的线程能不能被抢占，全靠判断这个整数是否是0。这里的线程包括了用户空间的进程的概念，在内核中对应的也是一个线程。当这个整数为0的时候，当前线程就能被抢占，否则不能。

软中断是一个普通的内核线程，与其他的内核线程一样，都参与内核线程的统一调度。软中断的实现是每一个CPU对应一个内核线程ksoftirqd，所以，有多少个CPU就会有多少个ksoftirqd内核线程。

Softirq依赖一个softirq_vec数组执行软中断。每一个数组内容对应一个Action，相当于一个中断向量（仿照硬中断进行的设计）。虽然所有的核共享这个数组，但不是每个核都要执行这个数组里的所有任务，每个核都有一个本地数据，用来指明当前核所需要承担的软中断任务。由于是共享一个softirq_vec，理论同一个任务都可以被所有的核对应的ksoftirq内核线程所执行。

由于软中断的内部是用户可以注册的任意的软中断函数，在这内部用户的行为一定程度是不可控的。所以软中断系统在调用每一个软中断的action的时候，都会保存preempt的值，在执行结束后复原这个值。这个值的作用很大，一个CPU一个值，如果非0，就代表这个CPU不能发生抢占，只有这个值是0的时候，当前的线程才能被抢占。也就是说，当我不希望被别人抢占的时候，只需要将这个数设置为非0即可。一般调用一下preempt_count_inc就可以将这个数自增1来达到目的。设置的就是当前CPU的计数器。对其他CPU并不影响。

Tasklet是基于Softirq功能进行实现的，实现的方法就是在一个特定的数组位置定义了一个action，仅此而已。但是由于Tasklet在内部进行了中断和抢占的设置，会显然Tasklet与其他的Softirq行为上不太一样。Tasklet相当于在Softirq之上多了一层保证，两个相同的Tasklet不会同时执行。也就是说不存在软中断上下文重入的问题。除此之外，Tasklet就是个普通的软中断的一个action而已。内核中的Timer也是软中断的一种。同一个软中断是可以在不同的核上同时执行的（但是不能在同一个核上重入），而同一个tasklet不可以同时在不同的核上执行，显然也不能在一个核上重入。

由于一个软中断只是一个普通的内核线程，所以它和其他的内核线程一样参与内核的进程调度。只是软中断的内部动不动就会操作抢占和软中断的使能函数，所以显得软中断会比较特殊。更特殊的是，软中断的入口函数是__do_softirq，这个函数在一开始就会把本核的preempt关掉，也就是说，软中断在执行的过程中，不允许在本核被抢占。那么带来的结果就是，如果在软中断里面阻塞了，将永远阻塞。就是完全死锁。这也是软中断的难度之一。

假设有一个软中断的函数和一个用户上下文的函数操作同一个自旋锁（这在内核模块的编程中很常见），用户空间锁了这个自旋锁之后，软中断打断了用户空间对应的内核模块函数的执行，软中断继续来加锁，就会导致用户空间的锁永远不能释放，软中断就会永久死锁。所以一般在这种情况的用户上下文需要先把软中断关掉才能进行加锁。这个情况最典型的是用户空间上下文和软中断上下文要操作同一个自旋锁的时候。也正是因为软中断在进入的时候关闭了preempt，禁止了抢占，所以在软中断内部禁止调用可以阻塞或者睡眠的函数，因为这会导致软中断被调度出当前的CPU，其他的内核线程被调度来执行。而这个时候，preempt已经关闭，这样就相当于了所有的内核线程都是在禁止抢占的环境下执行的，这显然会带来严重的问题。所以软中断是绝对禁止调用阻塞式的函数的。

另外，软中断和preempt计数器的关系是很巧妙的设计。每一个CPU核对应的preempt计数器都是一个32位的整数。软中断和硬中断在进入的时候都会禁止抢占，而他们禁止的时候设置的位是不一样的。我们知道这个整数只要是非0就不可以被抢占。内核为了区分当前到底是谁在禁止抢占，在这32位的整数上做了很多文章。对这个整数进行了位空间的划分。不同类型的抢占对应不同的位。这样就可以区分不同的专用抢占了。所以软中断和硬中断在禁止抢占的时候，并不是简单的调用自增，而是调用一个增加函数，增加的值就是他们对应的位。例如软中断是__local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET); 这个SOFTIRQ_OFFSET对应的就是软中断的位偏移。

如果需要local_bh_disable()来保护进程的临界区。比如，进程A和某个tasklet都会访问一个共享数据结构，semaphore和mutex不行，因为tasklet有可能运行中中断上下文。 spinlock也不行。

如果进程A先获得spinlock, 然后被tasklet打断，在tasklet也去获取同义把spinlock, 就会死锁。这时就需要在进程A中调local_bh_disable()，在临界区结束时调local_bh_enable()。这样保证在临界区中，不会被tasklet所打断。

实际代码中，一般都是spin_lock_bh()，相当于local_bh_disable()加spin_lock()。关键的代码是软中断的入口处的代码，如下：

```
asmlinkage __visible void do_softirq(void)
{
__u32 pending;
unsigned long flags;
if (in_interrupt())
return;
local_irq_save(flags);
pending = local_softirq_pending(); 
if (pending && !ksoftirqd_running())
do_softirq_own_stack();
local_irq_restore(flags);
}
```

实际的软中断的执行之前，都会调用一个in_interrupt的判断，字面意义是如果发现自己已经在软中断内部了，就不再执行软中断。所以，同一个CPU的软中断是不可能被另外一个软中断抢占的。in_interrupt函数仅仅是一个查看当前preempt整数对应的中断的位有没有被设置的判断（包括硬中断和软中断），所以关闭软中断的操作就会很简单：

```
static __always_inline void __local_bh_disable_ip(unsigned long ip, unsigned int cnt) 
{ 
preempt_count_add(cnt); 
barrier(); 
}

static inline void local_bh_disable(void) 
{ 
__local_bh_disable_ip(_THIS_IP_, SOFTIRQ_DISABLE_OFFSET); 
}
```

只是是一个简单的设置这个preempt整数的操作，使得当前CPU处于一个中断上下文中。而，这个函数不止是中断处理程序才会调用，用户自己写的模块也可以调用。

也就是说，用户的内核模块，在用户进程上下文的时候，想要与软中断上下文争夺一个自旋锁的时候，就需要在用户进程上下文对应的内核模块函数中将软中断关掉。关闭软中断在软中断本身看来就是有其他的软中断在运行。所以实际上，这个操作是欺骗软中断系统有其他的软中断在运行了，你就不能运行了。这也是软中断不能同时运行抢占的原因。

由于用户在这个CPU上调用 local_bh_disable的时候，一定是一轮的软中断已经运行结束的时候，所以当前关闭软中断就不会和ksoftirqd冲突。一轮的软中断执行会遍历当前CPU pending的所有软中断，直到执行结束，软中断才会让出CPU。出现pending就一定是硬中断的干的，因为硬中断才是负责源源不断的给软中断输出内容的机制。也就只有硬中断能够抢占软中断。

这里面就有一个尴尬的问题。如果硬中断可以打断软中断，那么在硬中断退出的时候，怎么保证CPU的上下文是交还给软中断，而不是被调度引擎调度给用户进程了？如果这个得不到保证，软中断的所有不可被抢占的保证都白费了，因为这就相当于间接的允许被抢占。

为了解决这个问题，硬中断退出的时候有一个专门的操作：

```
void irq_exit(void) 
{ 
#ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED 
local_irq_disable(); 
#else 
WARN_ON_ONCE(!irqs_disabled()); 
#endif 
account_irq_exit_time(current); 
preempt_count_sub(HARDIRQ_OFFSET); 
if (!in_interrupt() && local_softirq_pending()) 
invoke_softirq(); 
tick_irq_exit(); 
rcu_irq_exit(); 
trace_hardirq_exit(); /* must be last! */ 
}
```

可以看到，在硬中断结束的时候，会检查当前CPU的软中断是否被挂起，如果挂起了，就主动的调度软中断。这一步是不把调度交给调度引擎的，而是直接在硬中断中强制调度。也就是说，虽然硬中断可以打断当前的软中断的执行，但是当硬中断执行结束的时候，必须要把CPU交还给被硬中断挂起的软中断。从而就解决了这个可能被间接抢占的问题。

这个把preempt按位区分功能的做法有一个很特殊的效果，就是有的功能是可以同时设置多个功能对应的位的。例如NMI也对应preempt整数的一些位，但是当进入NMI硬件中断的时候，它会同时设置NMI对应的位和硬件中断对应的位。

```
#define nmi_enter() \
do { \
printk_nmi_enter(); \
lockdep_off(); \ 
ftrace_nmi_enter(); \ 
BUG_ON(in_nmi()); \
preempt_count_add(NMI_OFFSET + HARDIRQ_OFFSET); \
rcu_nmi_enter(); \
trace_hardirq_enter(); \
} while (0)
```

设置的位越多，从效果上看，也就意味着权限越高。因为首先硬件中断对应的抢占位是只能由硬件中断来恢复的，NMI这种硬件中断做到了，即使其他的硬件中断恢复了硬件中断抢占位，其他人还是不能抢占当前的NMI上下文。因为还有一个NMI_OFFSET对应的抢占位没有被清0，而只要这个值不是零，就不能被抢占。这就意味着当发生NMI的时候，任何其他的硬件中断都不能将其抢占。这也就奠定了NMI在硬件中断中的最高优先级的地位。所以，NMI的全称叫做：NMI(non-maskable interrupt)，不可屏蔽中断。这从另外一个层面说明了屏蔽硬件中断的操作是将preempt的 HARDIRQ_OFFSET置位，而不会去操作NMI_OFFSET 。也就是说明了NMI的实现原理还是在这个32位整数上做文章，就是规定了硬件中断以外的位来作为抢占的开关。

在硬中断快要结束的时候，硬中断会在硬中断的函数栈内调用一次软中断的执行函数。这个时候，硬中断已经打开了硬中断，所以允许被抢占。这个上下文属于中断的BH，但是还不属于ksoftirqd的软中断内核线程的上下文。

由于硬中断进入这个BH的条件是当前没有处于中断中，这个中断包括了软中断，硬中断和不可屏蔽中断三种情况，处于任何一种情况下，这个硬中断BH下都不会进入软中断的处理逻辑。所以这部分的软中断逻辑运行是不会同时允许多个的。只要该CPU当当前有在这个BH逻辑中，其他的硬中断就不会进入。

这个逻辑的设计使得同一个软中断同时具备两个执行的环境。一个是在硬中断执行结束退出的时候，直接调用软中断执行，这个时候已经将硬中断打开。另外一个是在ksoftirqd中运行一个软中断，这个软中断执行的时候，是处于内核线程的上下文，接受内核线程调度的过程。一个简单的区别是，如果在ksoftirq中写一个死循环，该CPU是仍然可以执行其他的逻辑的，只是该CPU上的软中断逻辑会被永远卡住。但是如果在硬中断的BH执行了软中断，那么硬中断只可以被硬中断打断，但是打断之后又会回来软中断的执行，所以该CPU将会永久阻塞。

硬中断结束的时候调用软中断这个设计，使得当系统负载很低的时候，大部分的软中断都可以直接在硬中断结束的时候完成，而不需要进入ksoftirqd的软中断内核线程进行执行。省去了软中断的内核线程运行开销就节省了一定的性能。

但是有个矛盾的问题是，这种硬中断直接能处理玩的软中断的情况只会发生在资源占用率很低的情况。但是这种情况下，对资源的这点程度的节省又意义不大。所以在涉及到中断的性能的时候，仍然是需要关注ksoftirqd的性能，而是BH的性能。

内核对于这个preempt一个小小的整数所设计的复杂的机制，可谓精妙绝伦。

## 链接原理

符号重定位是编译过程和运行过程都要发生的动作。在编译的过程中，如果所有的代码都写到一个单独的文件，由于编译器以文件为单位进行编译，所以可以一次性的拿到所有的函数，那么就可以就地处理所有的符号。显然这样是编译器最喜闻乐见的事情。但是由于有外部库和工程组织的需要，不可能所有的代码都在一个文件中，编译器是用来满足开发人员的需要的，不是反过来。所以编译器就要想办法解决不同文件之间的链接问题。

编译器在编译一个文件的时候，会生成一个段的划分。这个划分通常名字大同小异（当然可以通过写link脚本改变段的命名和排布），但是.text, .data这种常用的代码段和数据段基本没有人会有其他想法。每个文件编译的时候生成了同样的.text段，链接器用来处理多个编译单元的（也就是.o文件），将这些文件链接在一起的时候，链接器的主要工作就是将同样的段进行合并。这个操作看起来简单，但是不断.o文件互相调用的情况该怎么解决呢？例如A文件调用了B文件的test函数，在编译A的时候看不到B中test函数的定义，那么这个A里面的B的test函数的地址该如何填充？链接器在进行链接的时候又该如何修正？

首先可以确定的是A里面在链接发生之前是肯定不能知道B中test的地址的，但是A里面的汇编结果的call指令的目的地址总需要填充个值。这个值就是0，就是在编译A的时候，发现A调用了别人的test函数，编译器会直接在call的A函数的位置填call 0地址，然后同时，在A的目标文件的一个.rel.text和.rel.data。这两个表叫做重定向表，用于在链接的时候组装不同的目标文件，一个是函数重定向，一个是数据重定向。里面存储的信息就是在A的某某偏移位置调用了test函数。当链接发生的时候，链接器查看A的重定向标发现A需要test的地址，然后在B的函数定义中查找test的定义和地址（是A和B的.text合并之后的地址），然后用这个地址去修改A对应的偏移里面的call指令。这样就完成了链接时的重定位。

这个重定位发生在所有的静态链接的时候，包括静态链接库的时候和链接自己的代码文件的时候。

但是我们知道还有一个很常见的应用是动态链接。动态链接的时候，符号的位置要在运行的过程中才会解析。编译的时候分为PIC的编译方式和非PIC的传统编译方式（现在大部分库都是使用PIC的方式）。两个的区别在于能不能在内存中重用库的代码。非PIC的传统编译方式需要在加载库的时候就重新设置所有的符号。例如liba.so里面调用了libb.so里面的一个函数test，那么按照静态链接的思路liba.so需要暴露一个段里面存放需要重定位的符号（也就是 call test的偏移），在加载libb.so的时候就要立刻解析条虫liba.so里面的call指令对应的test函数的地址。这种情况相当于liba.so的.text段的内容在加载的时候被修改了。也就是说liba.so的.text的位置在不同的程序里面是不一样的（因为libb.so在不同的进程不一定在同样的位置）。所以liba.so在内存中不能复用，也就是每个进程都要在内存中加载一份liba.so的.text，liba.so使用了多少次就需要加载多少份。

这样有问题吗？除了内存里有多份liba.so外，并没有什么问题。有一个特点是加载的时候需要解析全部的符号，即使没有用到的，这样加载的速度相对慢一些。

动态链接用到了.rel.dyn和.rel.plt（PLT：过程链接表）。前者是数据重定向，后者是函数重定向。两个段的功能与静态链接的重定向表是一样的。这一切都显得那么轻松。

但是毕竟程序员是追求完美的，针对这两个问题，追求完美的程序员想出了PIC模式。所谓的PIC模式就是位置无关，就是想办法让liba.so的.text在所有使用liba.so的进程之间复用。这样只依赖.rel.dyn和.rel.plt可能就做不到了。因为使用这两个表是需要修改.text段的内容的。所以又添加了.got和.got.plt两个表，同样的，前者对应数据，后者对应函数。这两个段就是PIC的实现方法了。

所谓的PIC就是在编译liba.so的call test函数的时候，不是在test函数的地址位置填充0，而是填充liba.so的.got.plt段的test地址。在编译的时候.got.plt中的test的地址是空的，显然是不能寻址的，但是call test指令却是直接固定的调用.got.plt的表的test函数的（虽然这个函数还不知道在哪定义）。.got.plt相当于一个桩子，call test就是调用了这里的桩子函数。由于.got.plt不是位于.text里面，所以在解析的时候只需要修改.got.plt里面的test的定义地址就可以找到真实的定义，无论libb.so加载到内存的什么位置，都是只需要找到它，然后填充liba.so的.got.plt的test函数条目即可。如此.text就可以实现复用了。第一个问题解决。

第二个问题就是延迟绑定的技术。这个技术是为了防止加载的时候解析所有的符号，而是让用的时候才解析。所需要的技术在应用了PIC之后几乎是现成的。就是.got.plt中的内容不是加载的时候填充，而是用到的时候填充。这一切由运行时的链接器完成（interpreter）。
