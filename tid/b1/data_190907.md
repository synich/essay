# SQL的行转列与列转行

## 行转列

指把键值关系表（如从BerkleyDB导入的数据），变成围绕一个中心元素的详细表（列通常会很多）。就从原始的很多行的KV数据，变成行数很少（因为有重复）但很宽的形式，所以叫行转列。case when和group by是典型写法

```
select name,
  max(case course when 'math' then score else 0 end) math,
  max(case course when 'phy' then score else 0 end) physical
from rel_score
group by name;
```

course列被case多次，从而实现从窄表变成宽表。我把这种一个列变成多个列称为影分身，行转列一定伴随着影分身。

### 利用Hive的map类型实现 up 23.05.06

需求是从轨迹表，计算出每个实体在每通道的每小时出现总次数。

第一步先得到行表： `GROUP BY id, channel, from_unixtimestamp(captime, 'yyyy-MM-dd HH')` 。注意GROUP BY只能支持expr，不能用alias，所以最后的udf结果不能as，需要在SELECT时候重新写一遍再as hh，不确定会不会优化掉。

第二步对第一步的行表再做一次 `GROUP BY id, channel, substr(hh, 1, 10)` 接着在SELECT中，使用collect_list(substr(hh, -2) || cnt)把小时标记，和每个小时的次数拼接成array。接着再用str_to_map(concat_ws(array))把array变成标量的map值。得到包含 id, channel, map 的行表，此时的map有最小1个最多24个kv对，已经基本达成目的了。

最后一步就是从map分别取出24小时，再用nvl将不存在的值转成0。

整个过程中，最难想到但也最妙的自然就是第二步，利用collect_list这个UDAF函数再结合map类型，将每个分组的内容放在一行内，使一维行表具备更高维度的内容（但似乎也破坏了范式？），从而为最后一步平铺准备好了素材。不过这个方法强依赖引擎，像SQLite只能支持group_concat一种UDAF，并且没有map类型。勉强能用group_concat构造出json，也能凑合实现，但不如Hive这么方便。

## 列转行

指把定义很宽的表（即列很多），变成每行只有A、B键值对的形式。经过这样的转换，行的数量会大大变多，所以叫列转行。union是典型写法

```
select name, 'math' course, math as score from lika
union
select name, 'phy' course, physical as score from lika
order by name, course;
```
