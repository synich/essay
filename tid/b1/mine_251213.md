# 大模型6性能优化

## 性能瓶颈

大Prompt结合多并发对性能影响极大。同样的硬件，4B的5并发+4K prompt速度还略差于14B的单并发+0.5K Prompt，所以对低端硬件来说缩短Prompt是有价值的。

## 训练优化

LoRa模式对训练组非常友好，不同目的的语料分开训练，互相不会干扰。但训出来的LoRa文件体积达到原始文件的1/20~1/10，以至于使用LoRa后性能拖慢10%～25%。加上MindIE不支持LoRa和prefix cache同时打开，在多并发场景时性能更是雪上加霜。

堆积语料的训练效果非常明显，似乎数量达到3万条左右，哪怕4B的模型都能超过14B的效果，而且训练4B不到6小时。这对垂直领域来说是非常适合的。

## 推理优化

对MindIE来说，对模型权重(safetensor)做组图有python和cpp两种模式：理论上cpp专为部署优化，性能更好，但实际速度没有更快，只是多了prefix cache功能，但似乎比较死板。而python组图就可以支持LoRa，并且更省内存。似乎nVidia上没有这些问题，可见推理框架要做成熟的技术难度很高。

KV Cache对推理很重要，没有LoRa的时候，将模型加载后的剩余内存都给KV Cache，工作得很好。使用LoRa后再用此策略会导致LoRa计算时无法分配到足够大的显存，只能采用固定大小方式留给KV Cache。因为LoRa本就不能共享KV Cache，所以显存留得少也没有大影响。

组图和融合是偏上层的优化，真正的矩阵加速还是要靠更偏硬件的库，对于MindIE来说就是ATB库和Ascend CL驱动，不过这块并不开源，无从得知究竟。