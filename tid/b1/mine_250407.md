# 数据挖掘3神经网络的比较和图像领域应用

## 各种网络的简单比较

对神经网络发展变化历程归纳如下：

1. DNN：即多层感知机MLP，也被称为前馈神经网络(Feed-forward Neural Networks)，每层神经元的信号只能向一层传播，样本的处理在各个时刻独立。
2. CNN：图像中存在固有的局部模式（如人脸中的眼睛、鼻子、嘴巴等），所以将图像处理和神将网络结合引出卷积神经网络CNN。CNN是通过卷积核将上下层进行链接，同一个卷积核在所有图像中是共享的，图像通过卷积操作后仍然保留原先的位置关系。
3. RNN：DNN无法对时间序列上的变化进行建模，但时间顺序对于自然语言处理、语音识别等应用非常重要。为了适应这种需求，出现了循环神经网络RNN。

不论哪种网络，在实际应用中常常都混合着使用，比如CNN和RNN在上层输出之前往往会接上全连接层，简单总结CNN(卷积神经网络)、RNN(循环神经网络)、DNN(深度神经网络)的内部网络结构的区别：

先说DNN，从结构上来说他和传统意义上的神经网络(NN)没什么区别。一开始的神经元不能表示异或运算，通过增加网络隐藏层数和引入sigmoid激活函数解决了该问题，并发现神经网络的层数直接决定了它对现实的表达能力。但是随着层数的增加会出现局部函数越来越容易出现局部最优解的现象，用数据训练深层网络有时候还不如浅层网络，并会出现梯度消失的问题。为了克服梯度消失，使用ReLU、maxout等激活函数代替了sigmoid，形成了如今DNN的基本形式。

CNN与RNN的比较

相同点

1. 传统神经网络的扩展。
2. 前向计算产生结果，反向计算模型更新。
3. 每层神经网络横向可以多个神经元共存,纵向可以有多层神经网络连接。

不同点

1. CNN空间扩展，神经元与特征卷积；RNN时间扩展，神经元与多个时间输出计算
2. RNN可以用于描述时间上连续状态的输出，有记忆功能，CNN用于静态输出
3. CNN可以达到1000+深度，RNN深度有限

在RNN中，神经元的输出可以在下一个时间段直接作用到自身，即第i层神经元在m时刻的输入，除了(i-1)层神经元在该时刻的输出外，还包括其自身在(m-1)时刻的输出。（t+1）时刻网络的最终结果，是该时刻输入和所有历史共同作用的结果，这就达到了对时间序列建模的目的。RNN可以看成一个在时间上传递的神经网络，它的深度是时间的长度。

这时"梯度消失"现象又要出现了，只不过这次发生在时间轴上。所以RNN存在无法解决长时依赖的问题。为解决上述问题，提出了LSTM（长短时记忆单元），通过cell门开关实现时间上的记忆功能，并防止梯度消失。在序列信号分析中，如果能预知未来，对识别一定也是有所帮助的。因此就有了双向RNN、双向LSTM，同时利用历史和未来的信息。

## 图像领域

一直沿着CNN的方向发展，最早取得突破的是Yann LeCun在1998年提出的LeNet，在32x32的小图片效果有突破，但不能处理大图片。但奠定了现代卷积神经网络的原型，即卷积，池化，全链接。

在这之后CNN的锋芒开始被SVM等手工设计的特征盖过。随着ReLU和dropout的提出，以及GPU和大数据带来的历史机遇，CNN在2012年迎来了历史突破，这一年的ImageNet上AlexNet一举夺冠，开启了神经网络识图的时代。但AlexNet没有在方法论上给出方向，之后的VGG使用一系列大小为3x3的小尺寸卷积核和pooling层构造深度卷积神经网络，取得了较好的效果。

2014年的ImageNet冠军是GoogLeNet，它的主要特点是网络不仅有深度，还在横向上具有"宽度"。2015年ImageNet的冠军ResNet（深度残差网络），更是将图像分类识别错误率降低到了3.6%，超过了正常人眼识别的精度，堪称革命性的创新。

### 文生图网络

24年几大主流厂商的技术原理各不相同：midjourney是GAN，SD是diffusion，dall-e是CLIP+VAE

GAN是早期的共识，在21年5月有些人发现diffusion的效果比GAN更稳定。同年底dall-e公开了CLIP模型，但没有公布训练过程，有点类似免费但闭源。有位德园的高中教师在discord发起动议，建立一个共享图片库，用于文生图的共建，SD的创始人也进了该群，在22年有了开源的SD。SD不是单一模型，而是多个部分和模型共同组成的系统。
