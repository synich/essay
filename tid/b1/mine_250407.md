# 数据挖掘3神经网络在图像领域的应用

图像领域一直沿着CNN的方向发展，最早取得突破的是Yann LeCun在1998年提出的LeNet，在32x32的小图片效果有突破，但不能处理大图片。但奠定了现代卷积神经网络的原型，即卷积，池化，全链接。

在这之后CNN的锋芒开始被SVM等手工设计的特征盖过。随着ReLU和dropout的提出，以及GPU和大数据带来的历史机遇，CNN在2012年迎来了历史突破，这一年的ImageNet上AlexNet一举夺冠，开启了神经网络识图的时代。但AlexNet没有在方法论上给出方向，之后的VGG使用一系列大小为3x3的小尺寸卷积核和pooling层构造深度卷积神经网络，取得了较好的效果。

2014年的ImageNet冠军是GoogLeNet，它的主要特点是网络不仅有深度，还在横向上具有"宽度"。2015年ImageNet的冠军ResNet（深度残差网络），更是将图像分类识别错误率降低到了3.6%，超过了正常人眼识别的精度，堪称革命性的创新。

## 文生图网络

24年几大主流厂商的技术原理各不相同：midjourney是GAN，SD是diffusion，dall-e是CLIP+VAE

GAN是早期的共识，在21年5月有些人发现diffusion的效果比GAN更稳定。同年底dall-e公开了CLIP模型，但没有公布训练过程，有点类似免费但闭源。有位德园的高中教师在discord发起动议，建立一个共享图片库，用于文生图的共建，SD的创始人也进了该群，在22年有了开源的SD。SD不是单一模型，而是多个部分和模型共同组成的系统。
