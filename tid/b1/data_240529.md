# 数仓开发总结

## 数据同步集市层

数仓结果要用于检索，必须同步到检索服务器，不同的检索服务器特性不同，同步方式也不能一概而论。

hive的overwrite特性使它天然适合产生全量数据，但是对于下游来讲，可能需要增量数据。纯增和纯删好说，变化部分的界定是个难点。另外变化部分和删除部分要怎么同步到下游，不同的数据库的特性不一样，导致变化数据的提供方式也是不一样的。

### 表数据库（GP、ES和Doris）

比较同步ES的区别，总结下来主要有3种模式

* insert

最简单的模式，应用场景是不变的流水数据，每种数据库都支持，区别在于分区键有没有限制。比如doris要求必须用datetime类型切日表，但hive源表没有相应的类型，为此还要改造数仓表。

* upsert

通过相同的主键实现覆盖，速度相比insert往往会慢一些，ES的upsert速度大约是insert的1/3

GP不支持此特性，如果要实现数据更新，只能通过拉链表并配合查询方的调整才能实现，比较复杂。

* AB表切换

是一种思想，哪怕DB原生不支持也能通过手动模拟，简单做法就是推送完成后，向另一个flag表写入标记。ES原生支持alias操作，使AB切换更便捷。

* delete

### JanusGraph

和前面几种数据库比起来，图数据库显得相当独特。没有表的概念或者说整个就是一张极宽的大表

由于没有多表，在批量删除时就很吃亏，只有删数据方式

## 任务同步

用kafka作为任务间同步机制，zk/hive和kafka虽然都能序列化，但本身的读写区别，导致不适用。类似数据结构要选型，在更大的层面就是对组件的选择。kafka可以比作stack，zk则类似map。kfk写入不关心导致不能指定读，适合批量消费却不关注具体内容，而锁的场景却天然是小数量但一定要适合具名读

## 分区与调度

时分区表命名困难，按小时调度，但周期是24，导致时分区前8位的天，不能和天分区表一样理解。特别是表名还带了gj

月表只在每月初跑一天，可靠性不够，应该触发多次并在第二次以后再决定要不要跳过
