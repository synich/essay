# 大模型实践

要跑大模型对显卡的算力要求非常高，我用的赛扬5095，算力不到200G flops，而手机芯片天玑6020有近500G flops，因此手机反而比电脑要快得多。

启动ollama

```
OLLAMA_HOST=0.0.0.0:11434
ollama serve&
```

启动open-webui，注意-p选项的顺序不要搞错，前面的是主机端口，后面是8080不要变。

```
docker run -d -e HF_ENDPOINT=https://hf-mirror.com -p 3080:8080 -e OLLAMA_BASE_URL=http://192.168.0.224:11434 -v open-webui:/app/backend/data --name open-webui --restart always swr.cn-north-4.myhuaweicloud.com/ddn-k8s/ghcr.io/open-webui/open-webui:main
```
