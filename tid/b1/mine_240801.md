# 大模型实践

要跑大模型对显卡的算力要求非常高，我用的赛扬5095，算力不到200G flops，而手机芯片天玑6020有近500G flops，因此手机反而比电脑要快得多。

启动脚本

```
OLLAMA_HOST=0.0.0.0:11434
ollama serve&
```

```
docker run -d -p 3000:3080 -e OLLAMA_BASE_URL=http://192.168.0.224:11434 -v open-webui:/app/backend/data --name open-webui --restart always swr.cn-north-4.myhuaweicloud.com/ddn-k8s/ghcr.io/open-webui/open-webui:main
```
