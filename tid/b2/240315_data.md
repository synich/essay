# 对大模型与的理解与思考

23年12月意外地被拉进大模型项目后大约跟了3个月，不得已学着理解这其中一些概念，一些不成熟的思考

## 模型相关概念

早期模型的权重和激活参数（tensor）是用PyTorch的pickle保存，现在主流的有huggingface设计的safetensor和ggml定义的gguf。

safetensor支持五种框架：pytorch、TensorFlow、flax（jax）、paddle（paddlepaddle）、numpy。

模型规模与量化

10B以下通常称为小模型，再结合量化方式就可以确定使用资源，比如7B模型如果用BF16，大小是`7G*2Byte=14G`；如果用Q4_0量化，大小是`7G*0.5Byte=4G`。量化由框架和硬件共同决定，至少有十多种，我所知常见的有fp16/int8/int4。

模型的核心结构是张量，我下载过1B的模型文件只有200个张量，平均每个张量的参数有500万之多。

## 传统机器学习分类概览

虽然ML已经日渐式微，但了解其思想才能更好地理解现在的方向。机器学习的目的有三大类：回归、分类、聚类。再辅以配套技术：降维、模型选择和预处理。

## 有监督-回归线性回归逻辑回归

## 有监督-分类

* KNN决策树
* 支持向量机
* SVM和朴素贝叶斯

## 无监督-聚类K-means

# 集成学习

将多个弱模型整合成一个强模型，有bagging和boosting两个流派

## bagging派之随机森林

## boosting派之XGBoost其实还有AdaBoost和GBDT，但XGBoost最有名

# 强化学习

在人工智能领域属于少见的行为主义学派（控制论）。实现时与神经网络关联很深，似乎只有AlphaGo成功了，似乎出了游戏领域没有成功的例子