# 离线工具实现流式计算的实践

## 离线计算的缺陷

传统的处理逻辑是：每日凌晨以后开始对上一个自然日的数据进行归档、计算，并在白天之前完成计算。也许对互联网公司的业务场景，这样是合适且够用的，但到了感知数据场景，存在几个严重的不足

1. 数据必然有延迟，导致每日凌晨以后，上一个自然日的数据往往没有齐备，这时启动计算肯定是不完备的
2. 数据计算部署在甲方且没有运维，一旦某天异常中断，下一次自动触发的计算结果会不正确

用流计算能解决这两个问题吗？理论上可以，但这又牵涉到团队技能栈、计算资源开销、切换等许多问题，加上数据计算(hadoop)和数据使用(ES/MySQL)在不同的存储，而且数量都很大，更新的成本很高。

## 解决思路

观察传统离线计算，是一种典型的无状态计算。每一次计算在固定时间被触发，且不知道上一次的计算状态。因此要从无状态向有状态切换，即每次的计算必须要知道上一次的计算条件，并延续计算，而不是被调度器的trigger_time定义的计算。

为了支持任意时间打断计算并恢复，一天一次触发会导致较多的空等时间，如果改为N小时一次，又会引发数据重算的问题，比较复杂。先讨论从无状态改为有状态的尝试。

## 项目实践

经过技战法和感知数智的实践，已经在一天一次的调度方式下解决了开头所列的两个问题。

外部存储选什么？常见的MySQL、Redis都会增加部署资源，考虑到读写便利性和记录的数量不大，使用ZNode来存储上一次计算状态。

为做到有状态，需要记录两种数据

1. 上一次计算的输入数量。如果下个周期输入的增幅达成一定阈值，要触发那天的重算
2. 上一次计算成功与否。显然如果失败的任务，下个周期也要触发重算

结合这两个特性，我把它命名为：自动补数据&自动续跑。上一次输入量或这次更新后的量，记录在lastrun路径；这一次要运行哪几天以及运行成功与否，记录在run_days路径。两个变量互为补充，必须同时修改。由于数仓结果还需要推送到集市层，后来又加了integrate路径，但本质和run_days是一样的。所以只要理解前两个就行。

基本理念不难，但落地时由于要对画布进行切分，加上每个ZNode的存储有上限，就导致最终的实现非常复杂。
